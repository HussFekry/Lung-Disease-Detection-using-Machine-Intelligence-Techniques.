{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python"
      ],
      "metadata": {
        "id": "Th25WpPYWw-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "import os\n",
        "import glob\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "LTkWyZBQXA79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import logging\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "3XNHPF0zXBIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_files(base_dir, target_dir):\n",
        "    count = 0\n",
        "    path = get_path(base_dir, target_dir)\n",
        "    for dirname, _, filenames in os.walk(path):\n",
        "        for filename in filenames:\n",
        "            count+=len(glob.glob(os.path.join(dirname, filename)))\n",
        "        return path, count\n",
        "\n",
        "def get_path(base_dir, target_dir):\n",
        "    path = os.path.join(base_dir,target_dir)\n",
        "    return path"
      ],
      "metadata": {
        "id": "pWaImWnIXBR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = 'E:/ML/Final/data'\n",
        "\n",
        "train_normal_dir = 'E:/ML/Final/data/train/normal'\n",
        "train_pneumonia_dir = 'E:/ML/Final/data/train/opacity'\n",
        "\n",
        "val_normal_dir = 'E:/ML/Final/data/val/normal'\n",
        "val_pneumonia_dir = 'E:/ML/Final/data/val/opacity'\n",
        "\n",
        "test_normal_dir = 'E:/ML/Final/data/test/normal'\n",
        "test_pneumonia_dir = 'E:/ML/Final/data/test/opacity'\n",
        "\n",
        "\n",
        "train_normal_path, train_normal_count = get_files(base_dir,train_normal_dir)\n",
        "train_pneumonia_path, train_pneumonia_count = get_files(base_dir,train_pneumonia_dir)\n",
        "\n",
        "val_normal_path, val_normal_count = get_files(base_dir,val_normal_dir)\n",
        "val_pneumonia_path, val_pneumonia_count = get_files(base_dir,val_pneumonia_dir)\n",
        "\n",
        "test_normal_path, test_normal_count = get_files(base_dir,test_normal_dir)\n",
        "test_pneumonia_path, test_pneumonia_count = get_files(base_dir,test_pneumonia_dir)\n",
        "\n",
        "print(\"No of Train Images: {}\".format(train_normal_count + train_pneumonia_count))\n",
        "print(\" \\u2022 No of Normal Images {}\".format(train_normal_count))\n",
        "print(\" \\u2022 No of Pneumonia Images {}\".format(train_pneumonia_count))\n",
        "\n",
        "print(\"No of Validation Images: {}\".format(val_normal_count + val_pneumonia_count))\n",
        "print(\" \\u2022 No of Normal Images {}\".format(val_normal_count))\n",
        "print(\" \\u2022 No of Pneumonia Images {}\".format(val_pneumonia_count))\n",
        "\n",
        "print(\"No of Test Images: {}\".format(test_normal_count + test_pneumonia_count))\n",
        "print(\" \\u2022 No of Normal Images {}\".format(test_normal_count))\n",
        "print(\" \\u2022 No of Pneumonia Images {}\".format(test_pneumonia_count))\n"
      ],
      "metadata": {
        "id": "VSNPmJudXBYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = []\n",
        "for filename in os.listdir(train_normal_path):\n",
        "    train_data.append((os.path.join(train_normal_path,filename),0))\n",
        "\n",
        "for filename in os.listdir(train_pneumonia_path):\n",
        "    train_data.append((os.path.join(train_pneumonia_path,filename),1))\n",
        "\n",
        "train_data = pd.DataFrame(train_data, columns=['image_path', 'label'], index=None)\n",
        "train_data = train_data.sample(frac=1).reset_index(drop=True)\n",
        "        \n",
        "val_data = []\n",
        "for filename in os.listdir(val_normal_path):\n",
        "    val_data.append((os.path.join(val_normal_path,filename),0))\n",
        "\n",
        "for filename in os.listdir(val_pneumonia_path):\n",
        "    val_data.append((os.path.join(val_pneumonia_path,filename),1))\n",
        "        \n",
        "val_data = pd.DataFrame(val_data, columns=['image_path', 'label'], index=None)\n",
        "        \n",
        "test_data = []\n",
        "for filename in os.listdir(test_normal_path):\n",
        "    test_data.append((os.path.join(test_normal_path,filename),0))\n",
        "\n",
        "for filename in os.listdir(test_pneumonia_path):\n",
        "    test_data.append((os.path.join(test_pneumonia_path,filename),1))\n",
        "\n",
        "test_data = pd.DataFrame(test_data, columns=['image_path', 'label'], index=None)\n",
        "print(\"Train Data {}\".format(train_data.shape))\n",
        "print(\"Validation Data {}\".format(val_data.shape))\n",
        "print(\"Test Data {}\".format(test_data.shape))"
      ],
      "metadata": {
        "id": "H9NgpATlXZtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "id": "89gG4qZYXZ0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_dict = {0:'Normal', 1:'Pneumonia'}\n",
        "train_data['class_name'] = train_data.label.map(class_dict)\n",
        "train_data['class_name'].value_counts().plot(kind='bar')"
      ],
      "metadata": {
        "id": "Efh9SRnYXaIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for filepath in train_data.image_path:\n",
        "    image = cv2.imread(filepath)\n",
        "    image_size = image.shape\n",
        "    break\n",
        "image_size"
      ],
      "metadata": {
        "id": "kXqM26YSXaZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualization\n",
        "def visualize_img(images):\n",
        "    fig = plt.figure(figsize=(20, 15))\n",
        "    for i,path in enumerate(images):\n",
        "        fig.add_subplot(4, 4, i+1, xticks=[], yticks=[])\n",
        "        img = cv2.imread(path)\n",
        "        plt.imshow(img)\n",
        "        plt.title(train_data[train_data.image_path == path].class_name.values[0])\n",
        "        \n",
        "for i in range(2):\n",
        "    images = train_data[train_data.label == i].image_path\n",
        "    images = np.random.choice(images , 8)\n",
        "    visualize_img(images)\n"
      ],
      "metadata": {
        "id": "aDLJUstnXakq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip(images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ViQwUNyVXauk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Augmentation\n",
        "BATCH_SIZE = 32\n",
        "IMG_SHAPE  = 224\n",
        "\n",
        "train_image_gen = ImageDataGenerator(rescale=1./255,\n",
        "                                     width_shift_range=0.1,\n",
        "                                     height_shift_range=0.1,\n",
        "                                     brightness_range=[0.2,1.0],\n",
        "                                     zoom_range=0.2,\n",
        "                                     horizontal_flip=True,\n",
        "                                     fill_mode='nearest')\n",
        "\n",
        "train_gen = train_image_gen.flow_from_dataframe(train_data,\n",
        "                                              x_col='image_path',\n",
        "                                              y_col='class_name',\n",
        "                                              class_mode='binary',\n",
        "                                              batch_size=BATCH_SIZE,\n",
        "                                              shuffle=True,\n",
        "                                              target_size=(IMG_SHAPE,IMG_SHAPE))"
      ],
      "metadata": {
        "id": "6cDfnr90Xa3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Preprocessing\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "train_lb = to_categorical(train_data.label, dtype = int)\n",
        "val_lb = to_categorical(val_data.label, dtype=int)\n",
        "\n",
        "train_data = train_data.reset_index().drop(labels='index', axis=1)\n",
        "y_train = pd.DataFrame(train_lb).add_prefix('label_')\n",
        "\n",
        "val_data = val_data.reset_index().drop(labels='index', axis=1)\n",
        "y_val = pd.DataFrame(val_lb).add_prefix('label_')\n",
        "\n",
        "train_data = pd.concat([train_data, y_train], axis=1)\n",
        "val_data = pd.concat([val_data, y_val], axis=1)\n",
        "\n",
        "print(\"Training set has {} samples\".format(train_data.shape[0]))\n",
        "print(\"Validation set has {} samples\".format(val_data.shape[0]))"
      ],
      "metadata": {
        "id": "uoV_RbM0XbAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Helper Functions\n",
        "BATCH_SIZE = 32\n",
        "IMG_SHAPE  = 224\n",
        "EPOCHS = 20\n",
        "\n",
        "def gen():\n",
        "    train_image_gen = ImageDataGenerator(rescale=1./255,\n",
        "                                         width_shift_range=0.1,\n",
        "                                         height_shift_range=0.1,\n",
        "                                         brightness_range=[0.2,1.0],\n",
        "                                         zoom_range=0.2,\n",
        "                                         horizontal_flip=True,\n",
        "                                         vertical_flip=True,\n",
        "                                         fill_mode='nearest')\n",
        "\n",
        "    train_gen = train_image_gen.flow_from_dataframe(train_data,\n",
        "                                              x_col='image_path',\n",
        "                                              y_col=[f'label_{x}' for x in np.arange(2)],\n",
        "                                              class_mode='raw',\n",
        "                                              batch_size=BATCH_SIZE,\n",
        "                                              shuffle=True,\n",
        "                                              target_size=(IMG_SHAPE,IMG_SHAPE))\n",
        "\n",
        "\n",
        "    val_image_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    val_gen = val_image_gen.flow_from_dataframe(val_data,\n",
        "                                              x_col='image_path',\n",
        "                                              y_col= [f'label_{x}' for x in np.arange(2)],\n",
        "                                              class_mode='raw',\n",
        "                                              batch_size=BATCH_SIZE,\n",
        "                                              target_size=(IMG_SHAPE,IMG_SHAPE))\n",
        "    return train_gen, val_gen"
      ],
      "metadata": {
        "id": "uCB3l8LTYlUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot(history):\n",
        "\n",
        "    training_accuracy = history.history['accuracy']\n",
        "    validation_accuracy = history.history['val_accuracy']\n",
        "\n",
        "    training_loss = history.history['loss']\n",
        "    validation_loss = history.history['val_loss']\n",
        "\n",
        "    epochs_range=range(len(training_accuracy))\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_range, training_accuracy, label='Training Accuracy')\n",
        "    plt.plot(epochs_range, validation_accuracy, label='Validation Accuracy')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_range, training_loss, label='Training Loss')\n",
        "    plt.plot(epochs_range, validation_loss, label='Validation Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "coSxb8KrYleb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "def predict(image_path, model):\n",
        "    im = cv2.imread(image_path)\n",
        "    test_image = np.asarray(im)\n",
        "    processed_test_image = process_image(test_image)\n",
        "    processed_test_image = np.expand_dims(processed_test_image, axis = 0)\n",
        "    \n",
        "    ps = model.predict(processed_test_image)\n",
        "    return ps\n",
        "    \n",
        "def process_image(image):\n",
        "    image = tf.cast(image , tf.float32)\n",
        "    image = tf.image.resize(image , (224 , 224))\n",
        "    image = image/255\n",
        "    image = image.numpy()\n",
        "    return image"
      ],
      "metadata": {
        "id": "bVaOQ74pYln0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Building\n",
        "5.1 - VGG16\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "base = VGG16(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "for layer in base.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "vgg_model = Sequential()\n",
        "vgg_model.add(base)\n",
        "vgg_model.add(GlobalAveragePooling2D())\n",
        "vgg_model.add(BatchNormalization())\n",
        "vgg_model.add(Dense(256, activation='relu'))\n",
        "vgg_model.add(Dropout(0.5))\n",
        "vgg_model.add(BatchNormalization())\n",
        "vgg_model.add(Dense(128, activation='relu'))\n",
        "vgg_model.add(Dropout(0.5))\n",
        "vgg_model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "vgg_model.summary()"
      ],
      "metadata": {
        "id": "_0Z5AqabYlvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction on the training dataset\n",
        "train_gen, val_gen = gen()\n",
        "\n",
        "optm = Adam(lr=0.0001)\n",
        "vgg_model.compile(loss='binary_crossentropy', optimizer=optm, \n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "EarlyStopping = EarlyStopping(monitor='val_loss',\n",
        "                              min_delta=.0001,\n",
        "                              patience=3,\n",
        "                              verbose=1,\n",
        "                              mode='auto',\n",
        "                              restore_best_weights=True)\n",
        "\n",
        "model_save = ModelCheckpoint('./vgg16_model.h5',\n",
        "                             save_best_only = True,\n",
        "                             save_weights_only = False,\n",
        "                             monitor = 'val_loss', \n",
        "                             mode = 'min', verbose = 1)\n",
        "\n",
        "\n",
        "vgg_history = vgg_model.fit(train_gen,\n",
        "                             steps_per_epoch = train_gen.samples // BATCH_SIZE,\n",
        "                             epochs = 20,\n",
        "                             validation_data = val_gen,\n",
        "                             callbacks=[EarlyStopping, model_save],\n",
        "                             class_weight = class_weights)"
      ],
      "metadata": {
        "id": "FoU-xxB_Yy7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(vgg_history)"
      ],
      "metadata": {
        "id": "7CybFMWPYy-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(mob_history.history['val_accuracy'][-4])\n",
        "print(mob_history.history['val_loss'][-4])"
      ],
      "metadata": {
        "id": "r-aY2ejcZYdO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}